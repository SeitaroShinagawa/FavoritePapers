# Awesome dataset  
**Multi-object image datasets with ground-truth segmentation masks and generative factors**  
[[link](https://github.com/deepmind/multi_object_datasets)]  

**ToyADMOS dataset**  
[[link](https://zenodo.org/record/3351307#.XVIgPuj7Q2y)]  
[[code](https://github.com/YumaKoizumi/ToyADMOS-dataset)]  
[[paper](https://arxiv.org/abs/1908.03299)]  

**Anomaly detection**  
[[paper](http://openaccess.thecvf.com/content_CVPR_2019/html/Bergmann_MVTec_AD_--_A_Comprehensive_Real-World_Dataset_for_Unsupervised_Anomaly_CVPR_2019_paper.html)]  
[[link](https://www.mvtec.com/company/research/datasets/mvtec-ad/)]  

**iMaterialist Challenge (Fashion)**  
[[link](https://github.com/visipedia/imat_fashion_comp)]   
[[paper](https://arxiv.org/abs/1906.05750)]  

**CLEVR-Ref+: Diagnosing Visual Reasoning with Referring Expressions**  
*Runtao Liu, Chenxi Liu, Yutong Bai, Alan Yuille*  
[[paper](https://arxiv.org/abs/1901.00850)]  

**Kuzusiji MNIST (KMNIST)**  
[[link](http://codh.rois.ac.jp/kmnist/)]  

**Largest multi-label image database**  
[[link](https://github.com/Tencent/tencent-ml-images)]  

**A Corpus for Reasoning About Natural Language Grounded in Photographs**  
*Alane Suhr, Stephanie Zhou, Iris Zhang, Huajun Bai, Yoav Artzi*  
[[paper](https://arxiv.org/abs/1811.00491)]  
[[link](https://github.com/clic-lab/nlvr)]  

**MMD: Towards Building Large Scale Multimodal Domain-Aware Conversation Systems**  
[[paper](https://amritasaha1812.github.io/MMD/)]  

**The Metropolitan Museum of Art Open Access CSV and API**  
[[csv](https://github.com/metmuseum/openaccess)]  
[[API(https://metmuseum.github.io/)]  

**Art Institute of Chicago API**  
[[link](https://github.com/art-institute-of-chicago/data-service-collections)]  

**[sign language datasets](https://facundoq.github.io/unlp/sign_language_datasets/index.html)**  
finger spelling datasets

**SAVOIAS: A Diverse, Multi-Category Visual Complexity Dataset**  
*Elham Saraee, Mona Jalal, Margrit Betke*  
[[paper](https://arxiv.org/abs/1810.01771)]  

**TVQA DATASET**  
[[link](http://tvqa.cs.unc.edu/)]  

**google dataset search**  
[[link](https://toolbox.google.com/datasetsearch)]  

**Givson Environment (CVPR2018 spotlight)**  
[[project](http://gibsonenv.stanford.edu/)]  

**Cornell Natural Language Visual Reasoning (NLVR) dataset**  
[[link](http://lic.nlp.cornell.edu/nlvr/)]  

**Hierarchical Neural Story Generation**  
*Angela Fan, Mike Lewis, Yann Dauphin*  
[[paper](https://arxiv.org/abs/1805.04833)]  

**The NES Music Database: A multi-instrumental dataset with expressive performance attributes**  
*Chris Donahue, Huanru Henry Mao, Julian McAuley*  
[[paper](https://arxiv.org/abs/1806.04278)]  

**short-jokes-dataset**  
[[link](https://github.com/amoudgl/short-jokes-dataset)]  
231,657 short jokes scraped from various websites  

**Learning from Millions of 3D Scans for Large-scale 3D Face Recognition (CVPR2018)**  
*Syed Zulqarnain Gilani, Ajmal Mian*  
[[paper](https://arxiv.org/abs/1711.05942)]  
large-scale 3D facial dataset  

**SCUT-FBP5500-Database-Release**  
[[link](https://github.com/HCIILAB/SCUT-FBP5500-Database-Release)]    
facial dataset  

**BDD100K: A Large-scale Diverse Driving Video Database**  
[[project](http://bair.berkeley.edu/blog/2018/05/30/bdd/)]  

**VizWiz Grand Challenge: Answering Visual Questions from Blind People (CVPR2018)**  
*Danna Gurari, Qing Li, Abigale J. Stangl, Anhong Guo, Chi Lin, Kristen Grauman, Jiebo Luo, Jeffrey P. Bigham*  
[[paper](https://arxiv.org/abs/1802.08218)]  

**CoDraw: Visual Dialog for Collaborative Drawing**  
*Jin-Hwa Kim, Devi Parikh, Dhruv Batra, Byoung-Tak Zhang, Yuandong Tian*  
[[paper](https://arxiv.org/abs/1712.05558)]  
[[link](https://github.com/facebookresearch/CoDraw)]  

**Cartoon Set**  
avatar face image dataset  
[[link](https://google.github.io/cartoonset/index.html)]  

**NEWSROOM summarization dataset**  
[[link](https://summari.es/)]  

**STAIR Actions: A Video Dataset of Everyday Home Actions**  
*Yuya Yoshikawa, Jiaqing Lin, Akikazu Takeuchi*  
[[paper](https://arxiv.org/abs/1804.04326v1)]  

**Totally Looks Like - How Humans Compare, Compared to Machines**  
*Amir Rosenfeld, Markus D. Solbach, John K. Tsotsos*  
[[paper](https://arxiv.org/abs/1803.01485)]  
[[link](https://sites.google.com/view/totally-looks-like-dataset)]   

**Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection(ICCV2017)**  
[[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Dwibedi_Cut_Paste_and_ICCV_2017_paper.pdf)]  

**Let's Dance: Learning From Online Dance Videos**  
[[project](https://www.cc.gatech.edu/cpl/projects/dance/)]  

**BAM! The Behance Artistic Media Dataset for Recognition Beyond Photography**  
*Michael J. Wilber, Chen Fang, Hailin Jin, Aaron Hertzmann, John Collomosse, Serge Belongie*  
[[paper](https://arxiv.org/abs/1704.08614)]  
[[twitter](https://twitter.com/CVpaperChalleng/status/969576741244100608)]  

**VizWiz Grand Challenge: Answering Visual Questions from Blind People**  
*Danna Gurari, Qing Li, Abigale J. Stangl, Anhong Guo, Chi Lin, Kristen Grauman, Jiebo Luo, Jeffrey P. Bigham*  
[[link](https://arxiv.org/abs/1802.08218)]  

**MoCap dataset(motion capture)**  
[[link](http://mocap.cs.cmu.edu/)]  

**Pokemon splites**  
[[link](https://github.com/PokeAPI/sprites/)]  

**3D reconstruction data list**  
[[link](https://github.com/openMVG/awesome_3DReconstruction_list)]  

**BLOCKS Data Set**  
[[link](https://groundedlanguage.github.io/#PUBLICATIONS)]  

**End-to-end Recovery of Human Shape and Pose**  
[[link](https://akanazawa.github.io/hmr/)]  

**The KIT Motion-Language Dataset**  
*Matthias Plappert, Christian Mandery, Tamim Asfour*  
[[paper](https://arxiv.org/abs/1607.03827)]  
[[dataset](https://motion-annotation.humanoids.kit.edu/)]  

**Mozilla speech recognition dataset**  
[[link](https://voice.mozilla.org/data)]  

**UCF101**  
[[link](http://crcv.ucf.edu/data/UCF101.php)]  

**PubMed 200k RCT dataset: a large dataset for sequential sentence classification**    
Abstracts of papers?    
[[link](https://github.com/Franck-Dernoncourt/pubmed-rct)]  

**JSUT (Japanese speech corpus of Saruwatari Lab, University of Tokyo)**  
[[link](https://sites.google.com/site/shinnosuketakamichi/publication/jsut)]  

**AVA(google action recognition dataset)**  
[[link](https://research.google.com/ava/explore.html)]  

**Places: A 10 million Image Database for Scene Recognition**  
[[paper](http://places2.csail.mit.edu/PAMI_places.pdf)]  

**Google speech command dataset**  
[[link](https://research.googleblog.com/2017/08/launching-speech-commands-dataset.html)]  

**favicons**  
[[link](https://www.kaggle.com/colinmorris/favicons)]  

**青空文庫形態素解析データ集**  
[[link](http://aozora-word.hahasoha.net/index.html)]  

**SynthDigits**  
[[link](https://drive.google.com/file/d/0B9Z4d7lAwbnTSVR1dEFSRUFxOUU/view)]  

**mnist-m**  
[[link](https://drive.google.com/file/d/0B9Z4d7lAwbnTNDdNeFlERWRGNVk/view)]    

**Challenges of Data-to-Document Generation(EMNLP2017)**  
[[link](http://lstm.seas.harvard.edu/docgen/)]  

**Multi-Attribute Labelled Faces (abbreviated as MALF)**  
[[link](http://www.cbsr.ia.ac.cn/faceevaluation/)]  

**pixel level annotation of MS-COCO**  
[[link](https://github.com/nightrome/cocostuff)]  

**MF2 Training Dataset**  
[[link](http://megaface.cs.washington.edu/dataset/download_training.html)]  

**日本声優統計学会 声優統計コーパス**  
[[link](http://voice-statistics.github.io/)]  

**IKEA DATASET(Dataset for IKEA 3D models and aligned images)**  
[[link](http://ikea.csail.mit.edu/)]  

**The Kinetics Human Action Video Dataset**  
*Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, Mustafa Suleyman, Andrew Zisserman*  
[[paper](https://arxiv.org/abs/1705.06950)]  
[[project](https://deepmind.com/research/open-source/open-source-datasets/kinetics/)]  

**MANGA109**  
[[link](http://www.manga109.org/index.php)]  
日本の漫画データセット、学術利用目的のみ使用可能、アノテーションツール有り  

**Simple Vector Drawing Datasets**  
[[link](https://github.com/hardmaru/sketch-rnn-datasets)]  

**The Behance Artistic Media Dataset**  
[[link](https://bam-dataset.org/)]  

**CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning(CVPR2017)**  
[[project](http://cs.stanford.edu/people/jcjohns/clevr/)]  

**triviaQA: A Large Scale Dataset for Reading Comprehension and Question Answering**  
[[link](http://nlp.cs.washington.edu/triviaqa/)]  

**IMDB-WIKI – 500k+ face images with age and gender labels**  
[[project](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/)]  
[[qiita](http://qiita.com/yu4u/items/a2410f46669c5f20ee8e)]  

**STAIR caption(Japanese caption of MSCOCO)**  
[[link](https://stair-lab-cit.github.io/STAIR-captions-web/)]  
[[github](https://github.com/STAIR-Lab-CIT/STAIR-captions)]    

**Large-scale Fashion (DeepFashion) Database(ECCV2016)**  
[[paper](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html)]  

**Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding(ECCV2016)**  
*Gunnar A. Sigurdsson, Gül Varol, Xiaolong Wang, Ali Farhadi, Ivan Laptev, Abhinav Gupta*  
[[paper](https://arxiv.org/abs/1604.01753)]  
[[link](http://allenai.org/plato/charades/)]  

**AudioSet**  
[[link](https://research.google.com/audioset/)]    

**Aerial Informatics and Robotics Platform**  
ドローンのシミュレーションプラットフォーム  
[[link](https://www.microsoft.com/en-us/research/project/aerial-informatics-robotics-platform/)]  

**You-tube 8M**  
for action understandings  
[[link](https://research.google.com/youtube8m/)]   

**UCF101 - Action Recognition Data Set**  
動画認識用のデータセット  
[[link](http://crcv.ucf.edu/data/UCF101.php)]  

**THUMOS Challenge 2015**  
[[link](http://www.thumos.info/)]    

**The Food-101 Data Set**  
料理画像のデータセット  
[[link](https://www.vision.ee.ethz.ch/datasets_extra/food-101/)]  

**Advancing Research on Video Understanding with the YouTube-BoundingBoxes Dataset**  
You-tube動画のbounding box付きのデータセット  
[[link](https://research.googleblog.com/2017/02/advancing-research-on-video.html)]  

**pokemon dataset**  
[[link](https://www.kaggle.com/abcsds/pokemon)]  

**collection of vision and language**  
[[link](http://visionandlanguage.net)]  

##image & caption  
**1 Million Captioned Dutch Newspaper Images(LREC2016)**  
*Desmond Elliott and Martijn Kleppe*  
[[link](http://www.lrec-conf.org/proceedings/lrec2016/summaries/448.html)]  

**A Corpus of Images and Text in Online News**  
*Laura Hollink, Adriatik Bedjeti, Martin van Harmelen and Desmond Elliott*  
[[link](http://www.lrec-conf.org/proceedings/lrec2016/summaries/19.html)]  

**Cross-validating Image Description Datasets and Evaluation Metrics**  
*Josiah Wang and Robert Gaizauskas*  
[[link](http://www.lrec-conf.org/proceedings/lrec2016/summaries/591.html)]  

**Developing a Dataset for Evaluating Approaches for Document Expansion with Images**  
*Debasis Ganguly, Iacer Calixto and Gareth Jones*  
[[link](http://www.lrec-conf.org/proceedings/lrec2016/summaries/595.html)]  

**Humor in Collective Discourse: Unsupervised Funniness Detection in the New Yorker Cartoon Caption Contest**  
*Dragomir Radev, Amanda Stent, Joel Tetreault, Aasish Pappu, Aikaterini Iliakopoulou, Agustin Chanfreau, Paloma de Juan, Jordi Vallmitjana, Alejandro Jaimes, Rahul Jha and Robert Mankoff*  
[[link](http://www.lrec-conf.org/proceedings/lrec2016/summaries/317.html)]  

##Spken Dialog
**A Comparative Analysis of Crowdsourced Natural Language Corpora for Spoken Dialog Systems**  
*Patricia Braunger, Hansjörg Hofmann, Steffen Werner and Maria Schmidt*  
[[link](http://www.lrec-conf.org/proceedings/lrec2016/summaries/333.html)]  

##Question Answering Corpus 
**Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus**  
*Iulian Vlad Serban, Alberto García-Durán, Caglar Gulcehre, Sungjin Ahn, Sarath Chandar, Aaron Courville, Yoshua Bengio*  
[[paper](http://arxiv.org/abs/1603.06807)]  
[[corpus](http://agarciaduran.org/)]  

## Others
**Japanese Art**  
浮世絵、文献  
[[link](https://ukiyo-e.org/)]  
[[link](http://digitalcollections.nypl.org)]  　

**メトロポリタン美術館**  
CC0(creative commons zero)の絵画データセット(37万5000点)  
[[link](http://metmuseum.org/about-the-met/policies-and-documents/image-resources)]  
[[download csv](https://github.com/gregsadetsky/met-openaccess-images)]  

**Yahoo! WEBSCOPE**  
Yahooのホームページ、Yahooニュース、Yahooスポーツ、YahooファイナンスとYahoo不動産  
[[link](http://webscope.sandbox.yahoo.com)]  

**NicoNico data**  
コメントデータ、動画メタデータ、ニコニコ大百科データ  
[[link](http://www.nii.ac.jp/dsc/idr/nico/nico.html)]  

**RPG tsuku-ru 2D characters**  
[[link](http://yurudora.com/tkool/)]  
[[link](http://kobom.blog.fc2.com/)]  

##face  
**MS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition**  
[[link](http://arxiv.org/abs/1607.08221)]  

**WIDER FACE: A Face Detection Benchmark**  
[[link](http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/)]  

**IMDB-WIKI – 500k+ face images with age and gender labels**  
[[link](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/)]  

