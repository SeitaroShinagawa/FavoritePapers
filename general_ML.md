**A Theoretical Analysis of Contrastive Unsupervised Representation Learning**  
*Sanjeev Arora, Hrishikesh Khandeparkar, Mikhail Khodak, Orestis Plevrakis, Nikunj Saunshi*  
[[paper](https://arxiv.org/abs/1902.09229)]  

**A Comprehensive Survey on Graph Neural Networks**  
*Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu*  
[[paper](https://arxiv.org/abs/1901.00596)]  

**Anomaly detection tutorial (ICDM018 tutorial)**  
[[link](https://federation.edu.au/__data/assets/pdf_file/0011/443666/ICDM2018-Tutorial-Final.pdf)]  

**Resampled Priors for Variational Autoencoders**  
*Matthias Bauer, Andriy Mnih*  
[[paper](https://arxiv.org/abs/1810.11428)]  

**Outlier Detection using Generative Models with Theoretical Performance Guarantees**  
*Jirong Yi, Anh Duc Le, Tianming Wang, Xiaodong Wu, Weiyu Xu*  
[[paper](https://arxiv.org/abs/1810.11335)]  

**Discriminator Rejection Sampling**  
*Samaneh Azadi, Catherine Olsson, Trevor Darrell, Ian Goodfellow, Augustus Odena*  
[[paper](https://arxiv.org/abs/1810.06758)]  

**Supervising strong learners by amplifying weak experts**  
*Paul Christiano, Buck Shlegeris, Dario Amodei*  
[[paper](https://arxiv.org/abs/1810.08575)]  

**Differentiable Learning-to-Normalize via Switchable Normalization**  
*Ping Luo, Jiamin Ren, Zhanglin Peng*  
[[paper](https://arxiv.org/abs/1806.10779)]  

**Learning Confidence for Out-of-Distribution Detection in Neural Networks**  
*Terrance DeVries, Graham W. Taylor*  
[[paper](https://arxiv.org/abs/1802.04865)]  

**Neural Vector Spaces for Unsupervised Information Retrieval(TOIS2018)**  
*Christophe Van Gysel, Maarten de Rijke, Evangelos Kanoulas*  
[[paper](https://arxiv.org/abs/1708.02702)]  

**Skill Rating for Generative Models**  
*Catherine Olsson, Surya Bhupatiraju, Tom Brown, Augustus Odena, Ian Goodfellow*  
[[paper](https://arxiv.org/abs/1808.04888)]  

**A Dual Approach to Scalable Verification of Deep Networks (UAI2018 best paper)**  
*Krishnamurthy (Dj) Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, Pushmeet Kohli*  
[[paper](https://arxiv.org/abs/1803.06567)]  

**Which Training Methods for GANs do actually Converge? (ICML2018)**  
[[project](https://avg.is.tuebingen.mpg.de/research_projects/convergence-and-stability-of-gan-training)]  

**GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks (ICML2018)**  
*Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, Andrew Rabinovich*  
[[paper](https://arxiv.org/abs/1711.02257)]  

**Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics (CVPR2018)**  
*Alex Kendall, Yarin Gal, Roberto Cipolla*  
[[paper](https://arxiv.org/abs/1705.07115)]  

**Geometry Score: A Method For Comparing Generative Adversarial Networks (ICML2018)**  
*Valentin Khrulkov, Ivan Oseledets*  
[[paper](https://arxiv.org/abs/1802.02664)]  

**Classification and Geometry of General Perceptual Manifolds**  
[[paper](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.8.031003)]  

**Information Geometry Connecting Wasserstein Distance and Kullback-Leibler Divergence via the Entropy-Relaxed Transportation Problem**   
*Shun-ichi Amari, Ryo Karakida, Masafumi Oizumi*  
[[paper](https://arxiv.org/abs/1709.10219)]  

**Relational inductive biases, deep learning, and graph networks**  
*Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, Razvan Pascanu*  
[[paper](https://arxiv.org/abs/1806.01261)]  
[[slides(ja)](https://www.slideshare.net/DeepLearningJP2016/dlrelational-inductive-biases-deep-learning-and-graph-networks-104442091)]  

**Deep Energy: Using Energy Functions for Unsupervised Training of DNNs**  
*Alona Golts, Daniel Freedman, Michael Elad*  
[[paper](https://arxiv.org/abs/1805.12355)]  

**To understand deep learning we need to understand kernel learning**  
*Mikhail Belkin, Siyuan Ma, Soumik Mandal*  
[[paper](https://arxiv.org/abs/1802.01396)]  

**Progress & Compress: A scalable framework for continual learning (ICML2018)**  
*Jonathan Schwarz, Jelena Luketina, Wojciech M. Czarnecki, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, Raia Hadsell*  
[[paper](https://arxiv.org/abs/1805.06370)]  

**Reinforced Co-Training  (NAACL2018)**  
*Jiawei Wu, Lei Li, William Yang Wang*  
[[paper](https://arxiv.org/abs/1804.06035)]  

**Adafactor: Adaptive Learning Rates with Sublinear Memory Cost**  
*Noam Shazeer, Mitchell Stern*  
[[paper](https://arxiv.org/abs/1804.04235)]  

**Hyperspherical Variational Auto-Encoders**  
*Tim R. Davidson, Luca Falorsi, Nicola De Cao, Thomas Kipf, Jakub M. Tomczak*  
[[paper](https://arxiv.org/abs/1804.00891)]  

**InfoVAE: Information Maximizing Variational Autoencoders**  
*Shengjia Zhao, Jiaming Song, Stefano Ermon*  
[[paper](https://arxiv.org/abs/1706.02262)]  

**Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery(IPMI2017)**  
*Thomas Schlegl, Philipp Seeböck, Sebastian M. Waldstein, Ursula Schmidt-Erfurth, Georg Langs*  
[[paper](https://arxiv.org/abs/1703.05921)]  

**Graphical Models for Processing Missing Data**  
*Karthika Mohan, Judea Pearl*  
[[paper](https://arxiv.org/abs/1801.03583)]  

**Deep Learning for Sampling from Arbitrary Probability Distributions**  
*Felix Horger, Tobias Würfl, Vincent Christlein, Andreas Maier*  
[[paper](https://arxiv.org/abs/1801.04211)]  

**Learning to Compose Domain-Specific Transformations for Data Augmentation**  
*Alexander J. Ratner, Henry R. Ehrenberg, Zeshan Hussain, Jared Dunnmon, Christopher Ré*  
[[paper](https://arxiv.org/abs/1709.01643)]  
[[slide](https://www.slideshare.net/daynap1204/learning-to-compose-domainspecific-transformations-for-data-augmentation-85824441)]  

**Overcoming catastrophic forgetting with hard attention to the task**  
*Joan Serrà, Dídac Surís, Marius Miron, Alexandros Karatzoglou*  
[[paper](https://arxiv.org/abs/1801.01423)]  

**Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results(NIPS2017)**  
*Antti Tarvainen, Harri Valpola*  
[[paper](https://arxiv.org/abs/1703.01780)]  
[[project](https://github.com/CuriousAI/mean-teacher)]  

**Learning with Imprinted Weights**  
*Hang Qi, Matthew Brown, David G. Lowe*  
[[paper](https://arxiv.org/abs/1712.07136)]  

**MentorNet: Regularizing Very Deep Neural Networks on Corrupted Labels**  
*Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, Li Fei-Fei*  
[[paper](https://arxiv.org/abs/1712.05055)]  

**Investigating the Impact of Data Volume and Domain Similarity on Transfer Learning Applications**  
[[paper](https://arxiv.org/abs/1712.04008)]  

**Variational Memory Addressing in Generative Models(NIPS2017)**  
[[paper](https://papers.nips.cc/paper/6981-variational-memory-addressing-in-generative-models)]  

**Gradient Episodic Memory for Continual Learning(NIPS2017)**  
[[paper](https://papers.nips.cc/paper/7225-gradient-episodic-memory-for-continual-learning)]  

**Active Bias: Training More Accurate Neural Networks by Emphasizing High Variance Samples**  
[[paper](https://papers.nips.cc/paper/6701-active-bias-training-a-more-accurate-neural-network-by-emphasizing-high-variance-samples)]  

**Causal Generative Neural Networks**  
*Olivier Goudet, Diviyan Kalainathan, Philippe Caillou, Isabelle Guyon, David Lopez-Paz, Michèle Sebag*  
[[paper](https://arxiv.org/abs/1711.08936)]  

**Deep Hyperspherical Learning**  
*Weiyang Liu, Yan-Ming Zhang, Xingguo Li, Zhiding Yu, Bo Dai, Tuo Zhao, Le Song*  
[[paper](https://arxiv.org/abs/1711.03189)]  

**Metric Learning-based Generative Adversarial Network**  
*Zi-Yi Dou*  
[[paper](https://arxiv.org/abs/1711.02792)]   

**Don't Decay the Learning Rate, Increase the Batch Size**  
*Samuel L. Smith, Pieter-Jan Kindermans, Quoc V. Le*  
[[paper](https://arxiv.org/abs/1711.00489)]  

**Detecting annotation noise in automatically labelled data**  
[[paper](http://aclweb.org/anthology/P17-1107)]  

**Mutual Alignment Transfer Learning**  
*Markus Wulfmeier, Ingmar Posner, Pieter Abbeel*  
[[paper](https://arxiv.org/abs/1707.07907)]  

**Deep Attribute-preserving Metric Learning for Natural Language Object Retrieval(ACMMM2017)**    
*Jianan Li (Beijing Institute of Technology); Yunchao Wei (National University of Singapore); Xiaodan Liang (Carnegie Mellon University); Fang Zhao (National University of Singapore); Jianshu Li (National University of Singapore); Tingfa Xu (Beijing Institute of Technology); Jiashi Feng (National University of Singapore)*  

**Region-based Image Retrieval Revisited by Semantic Region Specification and Spatial Relationship Recommendation(ACMMM2017)**  
*Ryota Hinami (The University of Tokyo); Yusuke Matsui (National Institute of Informatics); Shin'Ichi Satoh (National Institute of Informatics)*  

**Robust Imitation of Diverse Behaviors**  
*Ziyu Wang, Josh Merel, Scott Reed, Greg Wayne, Nando de Freitas, Nicolas Heess*  
[paper](https://arxiv.org/abs/1707.02747)]  

**Meta-Learning with Temporal Convolutions**  
*Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, Pieter Abbeel*  
[[paper](https://arxiv.org/abs/1707.03141)]  

**Dual Supervised Learning**  
*Yingce Xia, Tao Qin, Wei Chen, Jiang Bian, Nenghai Yu, Tie-Yan Liu*  
[[paper](https://arxiv.org/abs/1707.00415)]  

**Variance Regularizing Adversarial Learning**  
*Karan Grewal, R Devon Hjelm, Yoshua Bengio*  
[[paper](https://arxiv.org/abs/1707.00309)]  

**Learning by Association - A versatile semi-supervised training method for neural networks**  
*Philip Häusser, Alexander Mordvintsev, Daniel Cremers*  
[[paper](https://arxiv.org/abs/1706.00909)]  

**Learning from Complementary Labels**  
*Takashi Ishida, Gang Niu, Masashi Sugiyama*  
[[paper](https://arxiv.org/pdf/1705.07541.pdf)]  

**Hyperparameter Optimization: A Spectral Approach**  
*Elad Hazan, Adam Klivans, Yang Yuan*  
[[paper](https://arxiv.org/abs/1706.00764)]  

**Self-Normalizing Neural Networks**  
*Günter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter*  
[[paper](https://arxiv.org/abs/1706.02515)]  

**The Cramer Distance as a Solution to Biased Wasserstein Gradients**  
*Marc G. Bellemare, Ivo Danihelka, Will Dabney, Shakir Mohamed, Balaji Lakshminarayanan, Stephan Hoyer, Rémi Munos*  
[[paper](https://arxiv.org/abs/1705.10743)]  

**Deep Learning is Robust to Massive Label Noise**  
*David Rolnick, Andreas Veit, Serge Belongie, Nir Shavit*  
[[paper](https://arxiv.org/abs/1705.10694)]  

**Neural Embeddings of Graphs in Hyperbolic Space**  
*Benjamin Paul Chamberlain, James Clough, Marc Peter Deisenroth*  
[[paper](https://arxiv.org/abs/1705.10359)]  

**Continual Learning with Deep Generative Replay**  
*Hanul Shin, Jung Kwon Lee, Jaehong Kim, Jiwon Kim*  
[[paper](https://arxiv.org/abs/1705.08690)]  

**Nonlinear Information Bottleneck**  
*Artemy Kolchinsky, Brendan D. Tracey, David H. Wolpert*  
[[paper](https://arxiv.org/abs/1705.02436)]  

**Grounded Recurrent Neural Networks**  
*Ankit Vani, Yacine Jernite, David Sontag*  
[[paper](https://arxiv.org/abs/1705.08557)]  

**Annealed Generative Adversarial Networks**  
*Arash Mehrjou, Bernhard Schölkopf, Saeed Saremi*  
[[paper](https://arxiv.org/abs/1705.07505)]  

**Real Time Image Saliency for Black Box Classifiers**  
*Piotr Dabkowski, Yarin Gal*  
[[paper](https://arxiv.org/abs/1705.07857)]  

**Cross-lingual Distillation for Text Classification**  
*Ruochen Xu, Yiming Yang*  
[[paper](https://arxiv.org/abs/1705.02073)]  

**Detecting Adversarial Samples Using Density Ratio Estimates**  
*Lovedeep Gondara*  
[[paper](https://arxiv.org/abs/1705.02224)]  

**A recurrent neural network without chaos**(ICLR2017)  
*Thomas Laurent, James von Brecht*  
[[paper](https://arxiv.org/abs/1612.06212)]  

**SafetyNet: Detecting and Rejecting Adversarial Examples Robustly**  
*Jiajun Lu, Theerasit Issaranon, David Forsyth*  
[[paper](https://arxiv.org/abs/1704.00103)]  

**Fast Generation for Convolutional Autoregressive Models**  
*Prajit Ramachandran, Tom Le Paine, Pooya Khorrami, Mohammad Babaeizadeh, Shiyu Chang, Yang Zhang, Mark A. Hasegawa-Johnson, Roy H. Campbell, Thomas S. Huang*  
[[paper](https://arxiv.org/abs/1704.06001)]  

**Softmax GAN**  
*Min Lin*  
[[paper](https://arxiv.org/abs/1704.06191)]  

**Overcoming Catastrophic Forgetting in Neural Networks**  
[[paper](https://arxiv.org/abs/1612.00796)]  
[[blog](http://rylanschaeffer.github.io/content/research/overcoming_catastrophic_forgetting/main.html)]  
[[qiita](http://qiita.com/yu4u/items/8b1e4f1c04460b89cac2)]  

**Applying Ricci Flow to Manifold Learning**  
*Yangyang Li*  
[[paper](https://arxiv.org/abs/1703.10675)]  

**Improved multitask learning through synaptic intelligence**  
*Friedemann Zenke, Ben Poole, Surya Ganguli*  
[[paper](https://arxiv.org/abs/1703.04200)]  

**Overcoming catastrophic forgetting in neural networks**  
[[paper](http://www.pnas.org/content/114/13/3521.full.pdf)]  
[[blog](http://rylanschaeffer.github.io/content/research/overcoming_catastrophic_forgetting/main.html)]  

**Guided Perturbations: Self Corrective Behavior in Convolutional Neural Networks**  
*Swami Sankaranarayanan, Arpit Jain, Ser Nam Lim*  
[[paper](https://arxiv.org/abs/1703.07928)]  

**Deformable Convolutional Networks**  
*Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, Yichen Wei*  
[[paper](https://arxiv.org/abs/1703.06211)]  

**Overcoming model simplifications when quantifying predictive uncertainty**  
*George M. Mathews, John Vial*  
[[paper](https://arxiv.org/abs/1703.07198)]  

**On the Expressive Power of Overlapping Operations of Deep Networks**  
*Or Sharir, Amnon Shashua*  
[[paper](https://arxiv.org/abs/1703.02065)]  

**Transfer Learning by Asymmetric Image Weighting for Segmentation across Scanners**  
*Veronika Cheplygina, Annegreet van Opbroek, M. Arfan Ikram, Meike W. Vernooij, Marleen de Bruijne*  
[[paper](https://arxiv.org/abs/1703.04981v1)]  

**Zero-Shot Recognition using Dual Visual-Semantic Mapping Paths**  
*Yanan Li, Donghui Wang, Huanhang Hu, Yuetan Lin, Yueting Zhuang*  
[[paper](https://arxiv.org/abs/1703.05002v1)]  

**Universal adversarial perturbations**  
[[paper](https://arxiv.org/pdf/1610.08401.pdf)]  

**Orthogonalized ALS: A Theoretically Principled Tensor Decomposition Algorithm for Practical Use**  
*Vatsal Sharan, Gregory Valiant*  
[[paper](https://arxiv.org/abs/1703.01804)]  

**A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models**  
*Chelsea Finn, Paul Christiano, Pieter Abbeel, Sergey Levine*  
[[paper](https://arxiv.org/abs/1611.03852)]  

**Variational Inference using Implicit Distributions**  
*Ferenc Huszár*  
[[paper](https://arxiv.org/abs/1702.08235)]  

**Depth Creates No Bad Local Minima**  
*Haihao Lu, Kenji Kawaguchi*  
[[paper](https://arxiv.org/abs/1702.08580)]  

**Generative Adversarial Networks in Estimation of Distribution Algorithms for Combinatorial Optimization**  
*Malte Probst*  
[[paper](https://arxiv.org/abs/1509.09235)]  

**Adaptive Neural Networks for Fast Test-Time Prediction**  
*Tolga Bolukbasi, Joseph Wang, Ofer Dekel, Venkatesh Saligrama*  
[[paper](https://arxiv.org/abs/1702.07811)]  

**Dynamic Filter Networks**  
[[slide](https://www.slideshare.net/daynap1204/dynamic-filter-networks-72013752?ref=https://www.rco.recruit.co.jp/career/engineer/blog/nipsicdm2016yomi/)]  

**Zero-Shot Learning posed as a Missing Data Problem**  
*Bo Zhao, Botong Wu, Tianfu Wu, Yizhou Wang*  
[[paper](https://arxiv.org/abs/1612.00560v2)]  

**Cosine Normalization: Using Cosine Similarity Instead of Dot Product in Neural Networks**  
*Luo Chunjie, Zhan jianfeng, Wang lei, Yang Qiang*  
[[paper](https://arxiv.org/abs/1702.05870)]  

**Dataset Augmentation in Feature Space**  
*Terrance DeVries, Graham W. Taylor*  
[[paper](https://arxiv.org/abs/1702.05538)]  

**PathNet: Evolution Channels Gradient Descent in Super Neural Networks**  
*Chrisantha Fernando, Dylan Banarse, Charles Blundell, Yori Zwols, David Ha, Andrei A. Rusu, Alexander Pritzel, Daan Wierstra*  
[[paper](https://arxiv.org/abs/1701.08734)]  

**Harmonic Networks: Deep Translation and Rotation Equivariance**  
*Daniel Worrall Stephan Garbin Daniyar Turmukhambetov Gabriel J. Brostow*  
[[project](http://visual.cs.ucl.ac.uk/pubs/harmonicNets/)]  

**Feature Space Modeling Through Surrogate Illumination**  
*Adam Gaier, Alexander Asteroth, Jean-Baptiste Mouret*  
[[paper](https://arxiv.org/abs/1702.03713)]  

**Supervised Learning for Controlled Dynamical System Learning**  
*Ahmed Hefny, Carlton Downey, Geoffrey J. Gordon*  
[[paper](https://arxiv.org/abs/1702.03537)]  

**Parallel Long Short-Term Memory for Multi-stream Classification**  
*Mohamed Bouaziz, Mohamed Morchid, Richard Dufour, Georges Linarès, Renato De Mori*  
[[paper](https://arxiv.org/abs/1702.03402)]  

**Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models**  
*Sergey Ioffe*  
[[paper](https://arxiv.org/abs/1702.03275)]  

**A More General Robust Loss Function**  
*Jonathan T. Barron*  
[[paper](https://arxiv.org/abs/1701.03077)]  

**Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities**  
[[paper](https://arxiv.org/abs/1701.06264)]  

次元削減について  
[[link](http://paper.hatenadiary.jp/entry/2016/10/31/082145)]  

**Language Modeling with Gated Convolutional Networks**  
*Yann N. Dauphin Angela Fan Michael Auli David Grangier (Facebook AI Research)*  
[[paper](https://arxiv.org/pdf/1612.08083v1.pdf)]  
LSTMを凌駕したらしいが果たして・・・  

**[Project] All Code Implementations for NIPS 2016 papers**  
[[link](https://www.reddit.com/r/MachineLearning/comments/5hwqeb/project_all_code_implementations_for_nips_2016/)]  

**Instance Weighting for Domain Adaptation in NLP(ACL2007)**  
[[paper](http://www.aclweb.org/anthology/P07-1034)]  

**MODE REGULARIZED GENERATIVE ADVERSARIAL NETWORKS**  
[[paper](https://openreview.net/pdf?id=HJKkY35le)]  

**IMPROVING GENERATIVE ADVERSARIAL NETWORKS WITH DENOISING FEATURE MATCHING**  
[[paper](https://openreview.net/pdf?id=S1X7nhsxl)  

**Unsupervised Learning of Sentence Representations using Convolutional Neural Networks**  
*Zhe Gan, Yunchen Pu, Ricardo Henao, Chunyuan Li, Xiaodong He, Lawrence Carin*  
[[paper](https://arxiv.org/abs/1611.07897)]  

**A Connection Between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models**  
*Chelsea Finn, Paul Christiano, Pieter Abbeel, Sergey Levine*  
[[paper](https://arxiv.org/pdf/1611.03852.pdf)]  

**Associative Adversarial Networks**  
*Tarik Arici, Asli Celikyilmaz*  
[[paper](https://arxiv.org/abs/1611.06953)]  

**f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization**  
*Sebastian Nowozin, Botond Cseke, Ryota Tomioka*  
[[paper](https://arxiv.org/abs/1606.00709)]  

**Generative Adversarial Nets from a Density Ratio Estimation Perspective**  
*Masatoshi Uehara, Issei Sato, Masahiro Suzuki, Kotaro Nakayama, Yutaka Matsuo*  
[[paper](https://arxiv.org/abs/1610.02920)]  

**Learning in Implicit Generative Models**  
*Shakir Mohamed, Balaji Lakshminarayanan*  
[[paper](https://arxiv.org/abs/1610.03483)]  

**One-shot Learning with Memory-Augmented Neural Networks**  
[[link](https://arxiv.org/abs/1605.06065)]  

**Building Machines that Imagine and Reason**  
[[link](http://shakirm.com/slides/DLSummerSchool_Aug2016_compress.pdf)]  

##Normalization  

##Adversarial Examples  
**Virtual Adversarial Training for Semi-Supervised Text Classification**  
[[paper](http://arxiv.org/abs/1605.07725)]  

**DISTRIBUTIONAL SMOOTHING WITH VIRTUAL ADVERSARIAL TRAINING(ICLR2016)**  
[[paper](http://arxiv.org/abs/1507.00677)]  
[[code](https://github.com/takerum/vat/)] 

**猫でも分かるVariational AutoEncoder**  
[[slideshare](http://www.slideshare.net/ssusere55c63/variational-autoencoder-64515581)]  
 
