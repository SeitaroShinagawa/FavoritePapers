# Multimodal  
**Self-supervised learning of visual features through embedding images into text topic spaces(CVPR2017)**  
[[paper](https://arxiv.org/pdf/1705.08631.pdf)]  
[[code](https://github.com/lluisgomez/TextTopicNet)]  

**SCAN: Learning Abstract Hierarchical Compositional Visual Concepts**  
*Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher P Burgess, Matthew Botvinick, Demis Hassabis, Alexander Lerchner*  
[[paper](https://arxiv.org/abs/1707.03389)]  

**Conditional generation of multi-modal data using constrained embedding space mapping**  
*Subhajit Chaudhury, Sakyasingha Dasgupta, Asim Munawar, Md. A. Salam Khan, Ryuki Tachibana*  
[[paper](https://arxiv.org/abs/1707.00860)]  

**Look, Listen and Learn**  
*Relja Arandjelović, Andrew Zisserman*  
[[paper](https://arxiv.org/abs/1705.08168)]  

**Recurrent Multimodal Interaction for Referring Image Segmentation**  
*Chenxi Liu, Zhe Lin, Xiaohui Shen, Jimei Yang, Xin Lu, Alan Yuille*  
[[paper](https://arxiv.org/abs/1703.07939)]  

**Visually grounded learning of keyword prediction from untranscribed speech**  
*Herman Kamper, Shane Settle, Gregory Shakhnarovich, Karen Livescu*  
[[paper](https://arxiv.org/abs/1703.08136v1)]  

**Cross-modal Deep Metric Learning with Multi-task Regularization**  
*Xin Huang, Yuxin Peng*  
[[paper](https://arxiv.org/abs/1703.07026)]  

**Fusion of EEG and Musical Features in Continuous Music-emotion Recognition(AAAI2017)**  
*Nattapong Thammasan, Ken-ichi Fukui, Masayuki Numao*  
[[paper](https://arxiv.org/abs/1611.10120)]  

